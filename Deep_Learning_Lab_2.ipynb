{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPeGkCa4sfVjtedVZE4DNJo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DoctorVinay8097/DLprojects/blob/main/Deep_Learning_Lab_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implement a python program to recognise characters. Use MNIST dataset for the same.**"
      ],
      "metadata": {
        "id": "08b_tRL3iwBN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Modified National Institute of Standards and Technology database.\n",
        "* The dataset consists of a large collection of 28x28 grayscale images of handwritten digits from 0 to 9.\n",
        "* These images are accompanied by corresponding labels indicating the actual digit represented by each image."
      ],
      "metadata": {
        "id": "WI2q14Q3vDs5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Image Size and Format:**\n",
        "\n",
        "\n",
        "The images in the MNIST dataset are grayscale, meaning they have only one channel (**black and white**). Each image has a resolution of 28x28 pixels, which makes them relatively small compared to modern datasets. The pixel values range from **0 to 255**, where **0 represents black and 255 represents white**."
      ],
      "metadata": {
        "id": "-gVaiHXdvcvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "image_instance = 10\n",
        "\n",
        "# Display the image\n",
        "_image = train_images[image_instance]\n",
        "ground_truth = train_labels[image_instance]\n",
        "\n",
        "# Plot the image and show the ground truth label\n",
        "plt.imshow(_image, cmap='gray')\n",
        "plt.title(f\"Ground Truth Label: {ground_truth}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "umlCWBG2vyly",
        "outputId": "0c593a49-5c2e-4d83-a012-c48c22ea0a46"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The shape of a single image sample or example: {_image.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sl50je8Ow1W4",
        "outputId": "37bb99c6-a62c-4cfb-fb30-9b983ac24a91"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of a single image sample or example: (28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Number of Samples:**\n",
        "\n",
        "The MNIST dataset contains a total of **70,000 samples**. These samples are divided into two main parts: the **training set and the test set**.\n"
      ],
      "metadata": {
        "id": "Nc29oAY8xekl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Set:**\n",
        "\n",
        "\n",
        "The training set consists of **60,000** images and their **corresponding labels**. These samples are used to train machine learning models to recognize and classify digits accurately. The training set is the part of the dataset that the model learns from."
      ],
      "metadata": {
        "id": "zvIpLXMdxxzb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test Set:**\n",
        "\n",
        "The test set contains **10,000 images and labels**. After training the model using the training set, it is evaluated using the test set to assess its **performance and generalization capabilities**. The test set is a way to measure how well the model can **generalize to new, unseen data.**"
      ],
      "metadata": {
        "id": "xjN-nvAdxy6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The shape of the training set: {train_images.shape}\")\n",
        "print(f\"The shape of the training labels: {train_labels.shape}\")\n",
        "print(f\"The shape of the test set: {test_images.shape}\")\n",
        "print(f\"The shape of the test labels: {test_labels.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUJN3TvAxWC6",
        "outputId": "0d8c940d-43b8-4ec7-92e5-f14113d35d97"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the training set: (60000, 28, 28)\n",
            "The shape of the training labels: (60000,)\n",
            "The shape of the test set: (10000, 28, 28)\n",
            "The shape of the test labels: (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Label Format:**\n",
        "\n",
        "\n",
        "The labels in the MNIST dataset are integers from 0 to 9, representing the actual digits that the images depict. For example, the label '5' corresponds to an image of the handwritten digit 5."
      ],
      "metadata": {
        "id": "9wQtxbwzy_vE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The steps we'll follow in this practical are as follows:\n",
        "\n",
        "1.   Import necessary libraries (Keras and Tensor flow)\n",
        "2.   Load and preprocess the MNIST dataset\n",
        "3.   Build a neural network model using Keras\n",
        "4.   Compile and train the model\n",
        "5.   Evaluate the model on the test set"
      ],
      "metadata": {
        "id": "QzSkgI1Di0We"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 1**: Import necessary libraries (**Keras and Tensor flow**)\n"
      ],
      "metadata": {
        "id": "MBaijmtMjO1d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **TensorFlow**, the elder of the two, was created by a group of researchers and engineers working at **Google Brain** in 2011 designed to facilitate and streamline the development of **deep neural networks**.\n",
        "\n",
        "* It quickly gained popularity due to its flexibility, scalability, and support for **distributed computing**.\n",
        "\n",
        "*  Deep learning frameworks overly **complex and difficult to work with.**\n",
        "\n",
        "\n",
        "* **Keras** was born out of the mind of **François Chollet**, a deep learning researcher and software engineer.\n",
        "\n",
        "* François created Keras as a **high-level neural network API**, capable of running on top of different deep learning backends, including TensorFlow. Keras was later integrated into TensorFlow in 2017 as its **official high-level API.**\n",
        "\n",
        "* TensorFlow provided the strong backbone and low-level capabilities, while Keras added a user-friendly interface that abstracted away much of the complexities of deep learning.\n",
        "\n"
      ],
      "metadata": {
        "id": "vmlac1yW16pI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "metadata": {
        "id": "bkWocLlejV6-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 2**: Load and preprocess the MNIST dataset\n"
      ],
      "metadata": {
        "id": "EbDYhdJFjdQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the images to values between 0 and 1\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Reshape the images to a 1D vector (flatten)\n",
        "train_images = train_images.reshape(train_images.shape[0], 28 * 28)\n",
        "test_images = test_images.reshape(test_images.shape[0], 28 * 28)\n"
      ],
      "metadata": {
        "id": "FQuiWGInjkN5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The shape of train_images: {train_images.shape}\")\n",
        "print(f\"The shape of train_images: {test_images.shape}\")"
      ],
      "metadata": {
        "id": "fggMPo1iN60J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 3**: Build a neural network model using Keras\n"
      ],
      "metadata": {
        "id": "2137qFnwj2YI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Sequential**\n",
        "* In Keras, Sequential is a class that represents a **linear stack of layers** in a neural network model.\n",
        "* It is a convenient way to build a simple feedforward neural network, where **data flows sequentially** from the input layer through the hidden layers to the output layer.\n",
        "* The Sequential class allows you to add layers one by one in a linear manner."
      ],
      "metadata": {
        "id": "_a6qjqINIvKl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dense**\n",
        "* In Keras, Dense is one of the fundamental layers used to create fully connected neural networks.\n",
        "* It is also known as a fully connected layer or a dense layer because each neuron in this layer is connected to every neuron in the previous and subsequent layers."
      ],
      "metadata": {
        "id": "hcLCAg6FMu-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=(784,)),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "fnUEbDOLjtY-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5e268ae-3ce9-4212-bb77-51b88e577ed9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 4**: Compile and train the model"
      ],
      "metadata": {
        "id": "D9qImnFtkGNV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In Keras, **model.compile()** is a method used to configure the training process for a neural network model.\n",
        "* It is one of the essential steps before training a model as it defines the **optimizer, loss function, and metrics** that the model will use during the training process."
      ],
      "metadata": {
        "id": "_vil2GuUQY42"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Optimizer**\n",
        "* In Keras, **Adam is an optimization algorith**m that is widely used for training deep learning models.\n",
        "* Adam stands for **Adaptive Moment Estimation**, and it combines the ideas of both Momentum and RMSprop algorithms.\n",
        "* It is well-suited for **large-scale and complex problems** and is known for its efficiency, fast convergence, and robustness to noisy data."
      ],
      "metadata": {
        "id": "3mZ6war_PuYP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Loss function**\n",
        "* Suitable for: **Multi-class classification problems** with integer labels (not one-hot encoded).\n",
        "* Formula:  - Σ(y_true * log(y_pred))\n",
        "* Description: Sparse categorical crossentropy is used when the class labels are represented as integers instead of one-hot encoded vectors. It saves memory and is convenient when you have a large number of classes."
      ],
      "metadata": {
        "id": "XccdFW3hQ-8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "# Create the model\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJ0iTv1MkCkj",
        "outputId": "6dd87069-669e-46cf-9b8b-5e8110830e8d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 4s 7ms/step - loss: 0.3590 - accuracy: 0.9010\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1729 - accuracy: 0.9509\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1231 - accuracy: 0.9646\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0940 - accuracy: 0.9730\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0759 - accuracy: 0.9783\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7c290327bcd0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 5**: Evaluate the model on the test set"
      ],
      "metadata": {
        "id": "XQ409wT3kRBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu9Kc0wqkLbo",
        "outputId": "e6242119-8fd0-46b8-94d5-ee19f6751b24"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0919 - accuracy: 0.9727\n",
            "Test accuracy: 0.9726999998092651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Different neural architecture"
      ],
      "metadata": {
        "id": "ISIIhxD8lGE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_2():\n",
        "    model = Sequential([\n",
        "        Dense(256, activation='relu', input_shape=(784,)),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Compile and train the model\n",
        "model_2 = create_model_2()\n",
        "model_2.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model_2.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss_2, test_accuracy_2 = model_2.evaluate(test_images, test_labels)\n",
        "print(f\"Architecture 2 - Test accuracy: {test_accuracy_2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p50iVt4vkjwN",
        "outputId": "21611c03-496b-4b1f-a761-a7c9d3a51da0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 6s 11ms/step - loss: 0.2575 - accuracy: 0.9255\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0952 - accuracy: 0.9711\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0634 - accuracy: 0.9800\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0450 - accuracy: 0.9857\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0330 - accuracy: 0.9897\n",
            "313/313 [==============================] - 2s 2ms/step - loss: 0.0870 - accuracy: 0.9745\n",
            "Architecture 2 - Test accuracy: 0.9745000004768372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rm6mc0-tlKpD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}